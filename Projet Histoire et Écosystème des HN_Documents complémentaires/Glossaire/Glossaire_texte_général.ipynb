{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UrG5XBg1M0Vp",
        "3G7Re9hYPInw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importer le texte"
      ],
      "metadata": {
        "id": "Tbf_aGhkNL-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Il faut penser à importer le texte en UTF8 dans le Colab**"
      ],
      "metadata": {
        "id": "5I4Qh_d_RSsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Le texte importé doit :\n",
        "- Être un texte BRUT exporté en encodage UTF8 (surtout pour le TAL : les\n",
        "modules étant souvent encodés comme cela)\n",
        "\n",
        "- Les mots voulus dans le glossaire doivent être précédés d'un astérisque\n",
        "(\"*\") SANS ESPACE (le mot ne sera pas reconnu)\n",
        "\n",
        "- Il doit être chargé dans le notebook avant toute procédure.\n",
        "\n",
        "- Vérifier la variable \"Chemin_du_texte\".\n",
        "Si elle n'est pas juste : copier et coller le chemin d'accès APRÈS\n",
        "avoir chargé le document.txt dans le notebook\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vm83UcpmSvy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Sur Colab: clic droit sur le fichier importé et copier le chemin d'accès\")\n",
        "Question_chemin = input( \"Quel est le chemin du texte ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMiUlfgUihaC",
        "outputId": "6ef0f628-5ed6-4747-e512-a07d54c837a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sur Colab: clic droit sur le fichier importé et copier le chemin d'accès\n",
            "Quel est le chemin du texte ?/content/texte glossaire.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Chemin_du_texte= Question_chemin"
      ],
      "metadata": {
        "id": "_mgMKpvTOVc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Oraison de l'âme fidèle se place dans la variable Oraison en tant que Chaîne de caractères\n",
        "txt=open(Chemin_du_texte, encoding=\"utf-8\").read()"
      ],
      "metadata": {
        "id": "yrNxj1idOBw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Définition du glossaire"
      ],
      "metadata": {
        "id": "O1Dbu3wsPF2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#définition du tri pour le glossaire (les mots dans le texte brut ont un \"*\" à l'initiale)\n",
        "def glossaire (texte):\n",
        "  mots=re.findall(r'\\*(\\w+)', texte)\n",
        "  return mots\n",
        "\n",
        "#Mise dans la variable la liste \"Glossaire\" avec les multiples occurences et non-triée\n",
        "Glossaire_txt = glossaire (txt)\n",
        "\n",
        "#Extraction des doublons en transformant la liste en set puis le set en liste: le set refuse les doublons\n",
        "Glossaire_txt_unique= list(set(Glossaire_txt))\n",
        "\n",
        "#Mise en minuscule de tous les termes dans la liste pour préparer le tri (les majuscules sont placées avant les minuscules)\n",
        "Glossaire_txt_unique=[mot.lower() for mot in Glossaire_txt_unique]\n",
        "\n",
        "#Tri par ordre alphabétique des mots à placer dans le glossaire\n",
        "Glossaire_txt_unique_trié = sorted (Glossaire_txt_unique)\n",
        "\n",
        "#Rendu visuel de tous les termes du glossaire\n",
        "for i in range (0, len(Glossaire_txt_unique_trié)):\n",
        "  print (Glossaire_txt_unique_trié[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJhKVzNwO8cO",
        "outputId": "0bad3bc1-337f-4f73-ae28-8d9c31814857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "admonneste\n",
            "baillé\n",
            "batture\n",
            "cerche\n",
            "chevestre\n",
            "confermée\n",
            "courroux\n",
            "cuydant\n",
            "cuyde\n",
            "cuyder\n",
            "desprens\n",
            "deuiser\n",
            "duisant\n",
            "effrayable\n",
            "ententive\n",
            "fange\n",
            "finée\n",
            "fouyr\n",
            "hydeur\n",
            "insques\n",
            "inénarrable\n",
            "ire\n",
            "labourage\n",
            "laidure\n",
            "laz\n",
            "maugré\n",
            "minée\n",
            "ord\n",
            "orde\n",
            "ouye\n",
            "ouyr\n",
            "oyt\n",
            "palus\n",
            "parquoy\n",
            "pensement\n",
            "placable\n",
            "prothocole\n",
            "rabbas\n",
            "revestu\n",
            "saillir\n",
            "sapience\n",
            "syme\n",
            "vesture\n",
            "vine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Création du glossaire"
      ],
      "metadata": {
        "id": "VuGUvi2Ae3Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "#création de la liste de chaînes : 1 élément de la liste = 1 vers\n",
        "def texte_en_vers(texte):\n",
        "    vers = [ligne.strip() for ligne in texte.split(\"\\n\") if ligne.strip()]\n",
        "    return vers\n",
        "\n",
        "\n",
        "def trouver_occurrences(glossaire, vers):\n",
        "\n",
        "    occurrences = {}\n",
        "    for mot in glossaire:\n",
        "        motif = r'\\b' + re.escape(mot.lower()) + r'\\b'\n",
        "        resultats = [\n",
        "            (i , v) for i, v in enumerate(vers) if re.search(motif, v.lower())\n",
        "        ]\n",
        "        if resultats:\n",
        "            occurrences[mot] = resultats\n",
        "    return occurrences\n",
        "\n",
        "#Création du fichier CSV (Excel) sous le format :\n",
        "#Terme, Nature (à ajouter), Occurences, Définition (à ajouter), Vers cité\n",
        "\n",
        "def creer_csv(occurrences, nom_fichier=\"glossaire_occurrences.csv\"):\n",
        "    with open(nom_fichier, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Terme\", \"Nature\", \"Occurrences (numéros de vers)\", \"Définition\", \"Vers correspondants\"])\n",
        "\n",
        "        for mot, infos in occurrences.items():\n",
        "            numeros = [str(num) for num, _ in infos]\n",
        "            vers_textes = [v for _, v in infos]\n",
        "\n",
        "            writer.writerow([\n",
        "                mot,\n",
        "                \"\",  # colonne Nature vide\n",
        "                \", \".join(numeros),\n",
        "                \"\",  # colonne Définition vide\n",
        "                \" / \".join(vers_textes)\n",
        "            ])\n",
        "    print(\"Fichier CSV créé\")\n"
      ],
      "metadata": {
        "id": "TfQh3KV7e6do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#On applique la liste qui permet de numéroter les vers\n",
        "vers=texte_en_vers(txt)\n",
        "\n",
        "#On chercher les occurences définies dans le glossaire dans les vers\n",
        "occurences=trouver_occurrences(Glossaire_txt_unique_trié, vers)\n",
        "\n",
        "#On génère le fichier CSV\n",
        "creer_csv(occurences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVZnxRif0tC",
        "outputId": "f21d60f9-5511-4089-ed7e-6f0ba2a9da8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fichier CSV créé\n"
          ]
        }
      ]
    }
  ]
}